{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스포일러(평점8~10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.naver.com/movie/bi/mi/point.naver?code=200065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "\n",
    "f = open('movie_p.txt','w')\n",
    "\n",
    "url = input('url: ')\n",
    "print('\\n')\n",
    "raw = requests.get(url)\n",
    "soup1 = bs(raw.text, 'html.parser')\n",
    "\n",
    "#각 댓글의 평점, 날짜, 댓글, 공감, 비공감, 논란지수\n",
    "iframe_url = soup1.iframe['src']\n",
    "final_url = \"https://movie.naver.com\"+iframe_url\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')\n",
    "\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):      # 관람객\n",
    "            if (reple[i].contents[5].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[5].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        else:                                                                # 관람객X\n",
    "            if (reple[i].contents[3].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[3].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "        if int(rev_star) >= 8:\n",
    "            dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "            text = dict_7['댓글']\n",
    "            f.write(text + '\\n')\n",
    "\n",
    "############################스포일러 보기 페이지로 넘어가기##################################\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=Y&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')  # 전체 댓글 수\n",
    "\n",
    "#데이터들을 저장할 딕셔너리 생성\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):    # 관람객\n",
    "            # 평점\n",
    "            rev_star = star[i].text\n",
    "            # 댓글\n",
    "            rev = reple[i].contents[5].text.strip()\n",
    "            # 댓글이 119자 이상일 때 \n",
    "            if len(rev) >= 119:\n",
    "                try:\n",
    "                    rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        else:                                                               # 관람객X\n",
    "            # 평점\n",
    "            rev_star = star[i].text\n",
    "            # 댓글\n",
    "            rev = reple[i].contents[3].text.strip()\n",
    "\n",
    "            if len(rev) >= 119:\n",
    "                try:\n",
    "                    rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "        if int(rev_star) >= 8:\n",
    "            dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "            text = dict_7['댓글']\n",
    "            f.write(text + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스포일러(평점1~4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.naver.com/movie/bi/mi/point.naver?code=200065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "\n",
    "f = open('movie_n.txt','w')\n",
    "\n",
    "url = input('url: ')\n",
    "print('\\n')\n",
    "raw = requests.get(url)\n",
    "soup1 = bs(raw.text, 'html.parser')\n",
    "\n",
    "#각 댓글의 평점, 날짜, 댓글, 공감, 비공감, 논란지수\n",
    "iframe_url = soup1.iframe['src']\n",
    "final_url = \"https://movie.naver.com\"+iframe_url\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')\n",
    "\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):      # 관람객\n",
    "            if (reple[i].contents[5].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[5].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        else:                                                                # 관람객X\n",
    "            if (reple[i].contents[3].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[3].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "        if int(rev_star) <= 4:\n",
    "            dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "            text = dict_7['댓글']\n",
    "            f.write(text + '\\n')\n",
    "\n",
    "############################스포일러 보기 페이지로 넘어가기##################################\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=Y&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')  # 전체 댓글 수\n",
    "\n",
    "#데이터들을 저장할 딕셔너리 생성\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):    # 관람객\n",
    "            # 평점\n",
    "            rev_star = star[i].text\n",
    "            # 댓글\n",
    "            rev = reple[i].contents[5].text.strip()\n",
    "            # 댓글이 119자 이상일 때 \n",
    "            if len(rev) >= 119:\n",
    "                try:\n",
    "                    rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        else:                                                               # 관람객X\n",
    "            # 평점\n",
    "            rev_star = star[i].text\n",
    "            # 댓글\n",
    "            rev = reple[i].contents[3].text.strip()\n",
    "\n",
    "            if len(rev) >= 119:\n",
    "                try:\n",
    "                    rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "        if int(rev_star) <= 4:\n",
    "            dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "            text = dict_7['댓글']\n",
    "            f.write(text + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스포일러X(평점8~10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.naver.com/movie/bi/mi/point.naver?code=200065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "\n",
    "f = open('movie_x_p.txt','w')\n",
    "\n",
    "url = input('url: ')\n",
    "print('\\n')\n",
    "raw = requests.get(url)\n",
    "soup1 = bs(raw.text, 'html.parser')\n",
    "\n",
    "#각 댓글의 평점, 날짜, 댓글, 공감, 비공감, 논란지수\n",
    "iframe_url = soup1.iframe['src']\n",
    "final_url = \"https://movie.naver.com\"+iframe_url\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')\n",
    "\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):      # 관람객\n",
    "            if (reple[i].contents[5].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[5].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        else:                                                                # 관람객X\n",
    "            if (reple[i].contents[3].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[3].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        if int(rev_star) >= 8:\n",
    "            dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "            text = dict_7['댓글']\n",
    "            f.write(text + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스포일러X(평점1~4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.naver.com/movie/bi/mi/point.naver?code=200065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "\n",
    "f = open('movie_x_n.txt','w')\n",
    "\n",
    "url = input('url: ')\n",
    "print('\\n')\n",
    "raw = requests.get(url)\n",
    "soup1 = bs(raw.text, 'html.parser')\n",
    "\n",
    "#각 댓글의 평점, 날짜, 댓글, 공감, 비공감, 논란지수\n",
    "iframe_url = soup1.iframe['src']\n",
    "final_url = \"https://movie.naver.com\"+iframe_url\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')\n",
    "\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):      # 관람객\n",
    "            if (reple[i].contents[5].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[5].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        else:                                                                # 관람객X\n",
    "            if (reple[i].contents[3].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 평점\n",
    "                rev_star = star[i].text\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[3].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "        if int(rev_star) <= 4:\n",
    "            dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "            text = dict_7['댓글']\n",
    "            f.write(text + '\\n')\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
