{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스포일러 txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.naver.com/movie/bi/mi/point.naver?code=200065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "#from selenium import webdriver\n",
    "\n",
    "f = open('movie2.txt','w')\n",
    "\n",
    "url = input('url: ')\n",
    "print('\\n')\n",
    "raw = requests.get(url)\n",
    "soup1 = bs(raw.text, 'html.parser')\n",
    "\n",
    "#각 댓글의 평점, 날짜, 댓글, 공감, 비공감, 논란지수\n",
    "iframe_url = soup1.iframe['src']\n",
    "final_url = \"https://movie.naver.com\"+iframe_url\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')\n",
    "\n",
    "dict_7 = dict()\n",
    "# count = 0\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):      # 관람객\n",
    "            if (reple[i].contents[5].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[5].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        else:                                                                # 관람객X\n",
    "            if (reple[i].contents[3].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[3].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "        text = dict_7['댓글']\n",
    "        f.write(text + '\\n')\n",
    "        \n",
    "################## 스포일러 보기 페이지로 넘어가기 ###################\n",
    "\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=Y&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')  # 전체 댓글 수\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "    star = soup3.select('body > div > div > div.score_result > ul > li > div.star_score > em')\n",
    "    like_and_dislike = soup3.select('body > div > div > div.score_result > ul > li > div.btn_area')\n",
    "    date = soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > dl > dt')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):    # 관람객\n",
    "            # 평점\n",
    "            rev_star = star[i].text\n",
    "            # 날짜\n",
    "            rev_date = date[0].contents[3].text.strip()[:10]\n",
    "            # 댓글\n",
    "            rev = reple[i].contents[5].text.strip()\n",
    "            # 댓글이 119자 이상일 때 \n",
    "            if len(rev) >= 119:\n",
    "                try:\n",
    "                    rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                except:\n",
    "                    continue\n",
    "            #좋아요        \n",
    "            rev_like = like_and_dislike[i].contents[1].contents[5].text\n",
    "            #싫어요\n",
    "            rev_dislike = like_and_dislike[i].contents[3].contents[5].text\n",
    "            #논란지수\n",
    "            if (rev_like == '0') and (rev_dislike != '0'):\n",
    "                contro = int(rev_dislike)\n",
    "            elif rev_like != '0':\n",
    "                contro = round(int(rev_dislike)/int(rev_like),4)\n",
    "\n",
    "        else:                                                               # 관람객X\n",
    "            # 평점\n",
    "            rev_star = star[i].text\n",
    "            # 날짜\n",
    "            rev_date = date[0].contents[3].text.strip()[:10]\n",
    "            # 댓글\n",
    "            rev = reple[i].contents[3].text.strip()\n",
    "\n",
    "            if len(rev) >= 119:\n",
    "                try:\n",
    "                    rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                except:\n",
    "                    continue\n",
    "            #좋아요        \n",
    "            rev_like = like_and_dislike[i].contents[1].contents[5].text\n",
    "            #싫어요\n",
    "            rev_dislike = like_and_dislike[i].contents[3].contents[5].text\n",
    "            #논란지수\n",
    "            if (rev_like == '0') and (rev_dislike != '0'):\n",
    "                contro = int(rev_dislike)\n",
    "            elif rev_like != '0':\n",
    "                contro = round(int(rev_dislike)/int(rev_like),4)\n",
    "                    \n",
    "        dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "        text = dict_7['댓글']\n",
    "        f.write(text + '\\n')\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스포일러X txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: https://movie.naver.com/movie/bi/mi/point.naver?code=200065\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "f = open('movie2_x.txt'.'w')\n",
    "\n",
    "url = input('url: ')\n",
    "print('\\n')\n",
    "raw = requests.get(url)\n",
    "soup1 = bs(raw.text, 'html.parser')\n",
    "\n",
    "#각 댓글의 평점, 날짜, 댓글, 공감, 비공감, 논란지수\n",
    "iframe_url = soup1.iframe['src']\n",
    "final_url = \"https://movie.naver.com\"+iframe_url\n",
    "url2 = final_url.replace('&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false','&type=after&onlyActualPointYn=N&onlySpoilerPointYn=N&order=sympathyScore')\n",
    "soup2 = bs(requests.get(url2).text, 'html.parser')\n",
    "cnt = soup2.select('body > div > div > div.score_total > strong > em')[0].text.replace(',','')\n",
    "\n",
    "dict_7 = dict()\n",
    "\n",
    "for page in range(1,int(cnt)//10+2 ): \n",
    "    url3 = url2+\"&page=\"+str(page)\n",
    "    raw3 = requests.get(url3)\n",
    "    soup3 = bs(raw3.text,'html.parser')\n",
    "    reple =  soup3.select('body > div > div > div.score_result > ul > li > div.score_reple > p')\n",
    "\n",
    "    for i in range(len(reple)):\n",
    "        if (reple[i].contents[3] == ' 스포일러 컨텐츠로 처리되는지 여부 '):      # 관람객\n",
    "            if (reple[i].contents[5].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[5].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[5].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "        else:                                                                # 관람객X\n",
    "            if (reple[i].contents[3].text.strip() == '스포일러가 포함된 감상평입니다. 감상평 보기'):\n",
    "                continue\n",
    "            else:\n",
    "                # 댓글\n",
    "                rev = reple[i].contents[3].text.strip()\n",
    "                # 댓글이 119자 이상일 때 \n",
    "                if len(rev) >= 119:\n",
    "                    try:\n",
    "                        rev = reple[i].contents[3].contents[1].contents[1]['data-src']   \n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "        dict_7['댓글'] = rev.replace('&#39;' ,'\\'').replace('&#34;','\\\"')\n",
    "        text = dict_7['댓글']\n",
    "        f.write(text + '\\n')\n",
    "        \n",
    "f.close()\n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
